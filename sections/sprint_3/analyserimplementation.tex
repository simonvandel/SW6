\subsection{Implementation of the Analyser}\label{sec:kernelDensityEstimation}

In order to fully understand the need for a good implementation of the analyser, we start with a quick rundown of the complexity of the unoptimized direct analysis algorithm seen in \cref{alg:unoptimised_algorithm}, which follows the mathematical formulas in \cref{sub:kernelDensityEstimation}.

\begin{center}
\captionof{algorithm}{Unoptimised algorithm}\label{alg:unoptimised_algorithm}
\begin{algorithmic}[1]

\Function{Analyser}{List points, List people, Bandwidth h}
\State Densities $\gets$ empty List
\State Velocities $\gets$ empty List
\State Turbulence $\gets$ empty List
\State Pressure $\gets$ empty List
\ForAll{points, x}
    \State KernelSum $\gets 0$
    \ForAll{people, P}
        \State KernelSum $\gets$ KernelSum $+$ \Call{Kernel}{|x - P|}
    \EndFor
    \State \Call{Densities.Add}{KernelSum $\cdot\; 2 / (\pi \cdot h^2)$}
\EndFor

\ForAll{points, x}
    \State KernelSum $\gets 0$
    \State VelocitySum $\gets 0$
    \ForAll{people, P}
        \State VelocitySum $\gets$ VelocitySum $+$ \Call{VelocityOf}{P} $\cdot$ \Call{Kernel}{|x - P|}
        \State KernelSum $\gets$ KernelSum $+$ \Call{Kernel}{|x - P|}
    \EndFor
    \State \Call{Velocities.Add}{VelocitySum $/$ KernelSum}
\EndFor

\ForAll{points, x}
    \State KernelSum $\gets 0$
    \State TurbuSum $\gets 0$
    \ForAll{People, P}%
        \State TurbuSum $\gets$ TurbuSum $+$ \Call{DirectionOf}{P} $\cdot$ \Call{Kernel}{|x - P|}
        \State KernelSum $\gets$ KernelSum $+$ \Call{Kernel}{|x - P|}
    \EndFor
    \State \Call{Turbulence.Add}{TurbuSum $/$ KernelSum}
\EndFor

\ForAll{points, x}
    \State KernelSum $\gets 0$
    \State PressSum $\gets 0$
    \ForAll{People, P}
        \State VelocityDiff $\gets$ |\Call{VelocityOf}{P} $-$ x.LocalVelocity|
        \State PressSum $\gets$ PressSum $+$ (VelocityDiff)$^2$ $\cdot$ \Call{Kernel}{|x - P|}
        \State KernelSum $\gets$ KernelSum $+$ \Call{Kernel}{|x - P|}
    \EndFor
    \State \Call{Pressure.Add}{x.LocalDensity $\cdot$ (PressSum $/$ KernelSum)}
\EndFor
\State\textbf{Return} (points, Densities, Velocities, Turbulence, Pressure)
\EndFunction
\end{algorithmic}
\end{center}

This algorithm has an asymptotic time complexity of $$\mathcal{O}(\text{points} \cdot \text{people})$$ which at first might seem decent. However, recall that the amount of points is related to the resolution, meaning that a point for every square meter at SmukFest, will result in 230.000 points\cite{smukFacts}. Combining this with potentially 50,000 festival guests\cite{smukFacts}, we reach an amount of potential calculation, for each analysis, that a regular server will struggle to evaluate within the real-time requirement of \cref{sec:s3_reqs}. We therefore want to reduce the complexity as much as possible.


\subsubsection{Reducing Complexity}

The first thing we need to reduce is the complexity. This would mean either the reduction of points or people.

Points can obviously be reduced, but not without also reducing the granularity of the result. But even if we reduce the number of points, we are not able to reduce the complexity. So if we want to reduce the complexity we need to reduce the amount of people iterated through. Considering that the kernel function will return zero for any person further away from the point than the bandwidth, we can reduce the complexity given that a reasonable bandwidth is used. This also relies on the reasonable assumption that people take up space, and that therefore we can only have a certain amount people inside a given bandwidth.

But before we can utilise this, we need a way to check if a person is further away than the bandwidth, without having to iterate through all the people. Luckily such a way exists in the form of R-trees. An R-tree is a data structure that takes $\mathcal{O}(n)$ to build, and allows us to do range searches in $\mathcal{O}(log(n))$ \cite{rtree}. If we start the analysis with building an r-tree of the people, each point would only have to query $\mathcal{O}(log(n)$ people, giving us the complexity of $$\mathcal{O}(\text{people} + \text{points} \cdot log(\text{people}) * PeopleWithinBandwidth(h))$$

Considering that there is a physical limit as too how dense people can be packed, the function $PeopleWithinBandwidth(h) = h^2 * \pi * maxDensity$. Since we at runtime will have a constant bandwidth, $h$, the final complexity will be $$\mathcal{O}(\text{points} \cdot log(\text{people}))$$.

\subsubsection{Parallel Computation}

Another way to increase the calculation of the analysis, is to take advantage of the embarrassingly parallel problem of calculating point. Since none of the calculations done for any individual point affect the the other points, we can calculate their values in parallel.

The problem  is embarrassingly parallel. Each point in the algorithm can be calculated independently of one another, allowing for a much wider  The calculation can be sped up by computing the calls to \emph{analysePoint} on multiple computational units.





\subsubsection{Reducing Constants}

Having reduced the complexity, we still need to reduce the amount of constants in our algorithm's run time. We wish to reduce the amount of iterations on the points, as well repeated calculations such as the Kernel values.

%% Hvorfor det er nice

\kanote{komment√©r koden}

%\LineComment{We reduce the amount of people using a range search}
%\LineComment{List of tuples containing individual Kernel values and velocity}
%\LineComment{Summarised Kernel variable adjusted for turbulence}

\begin{center}
\captionof{algorithm}{Optimised algorithm using RTree range search}\label{alg:revised_algorithm}
\begin{algorithmic}[1]

\Function{Analyser}{List points, rTree t, Bandwidth h}
\State Result $\gets$ Empty List 
\ForAll{points, p}
    \State CulledPeople $\gets$ \Call{t.inRange}{h,p} 
    \State Result $\gets$ Result + \Call{analysePoint}{p,CulledPeople}
\EndFor
\State \textbf{Return} Result

\EndFunction

\Function{analysePoint}{Point x, List[person] people}


\State KernelValSum $\gets 0$
\State NonNormalisedVelocitySum $\gets vector(0.0,0.0)$
\State NonNormalisedTurbulenceSum $\gets 0$
\State TurbulenceKernelValSum $\gets 0$ 


\ForAll{People, P}
    \State TmpKernelVal $\gets$ \Call{Kernel}{|x - P|}
    \State KernelValSum $\gets$ KernelValSum + TmpKernelVal
    \State NonNormalisedVelocitySum $\gets$ NonNormalisedVelocitySum + Velocity * TmpKernelVal
    \If{P.HeadingDirection is valid}
        \State NonNormalisedTurbulenceSum $\gets$ NonNormalisedTurbulenceSum + P.HeadingDirection * TmpKernelVal
        \State TurbulenceKernelValSum $\gets$ TurbulenceKernelValSum + TmpKernelVal
    \EndIf
\EndFor

\If{KernelValSum is 0}
    \State \textbf{Return} (0,(0,0),0,0)
\Else
    \State Density $\gets$ KernelValSum $\cdot \; 2 / (\pi \cdot h^2)$
    \State Velocity $\gets$ NonNormalisedVelocitySum / KernelValSum
    \State Turbulence $\gets$ 1 - ( NonNormalisedTurbulenceSum / TurbulenceKernelValSum )
    \State VelocityDiffSum $\gets$ 0
    \ForAll{People, P}
        \State VelocityDiff $\gets$ |P.velocity - Velocity|$^2 \cdot$ \Call{Kernel}{|x - P|}
        \State VelocityDiffSum $\gets$ VelocityDiffSum $+$ VelocityDiff
    \EndFor
    \State Pressure $\gets$ Density $\cdot$ ( VelocityDiffSum / KernelValSum )



\State \textbf{Return} (x, Density, Velocity, Turbulence, Pressure)
\EndIf
\EndFunction
\end{algorithmic}
\end{center}






